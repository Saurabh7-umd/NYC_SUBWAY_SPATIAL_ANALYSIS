{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "G4airCbgkJJ-",
   "metadata": {
    "id": "G4airCbgkJJ-"
   },
   "source": [
    "<center><h1><b>Subway Surfers </h1></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pi6IFw62EbYm",
   "metadata": {
    "id": "pi6IFw62EbYm"
   },
   "source": [
    "<p>\n",
    "  <img src=\"https://i.ytimg.com/vi/qbo8aX-oIew/maxresdefault.jpg\" alt=\"Logo\" width=\"700\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc234b-db46-4f5d-a193-2a3267b508ea",
   "metadata": {
    "id": "e7fc234b-db46-4f5d-a193-2a3267b508ea"
   },
   "source": [
    "# Project Overview\n",
    "Experience \"Subway Surfers,\" a data-driven adventure where your goal is to investigate the complex network that is the New York City subway system. Our crew navigates the digital rails like subway surfers, utilizing the vast network that is relied upon by 32% of New York City residents for their everyday commute.\n",
    "\n",
    "Equipped with our digital surfboards, we set out on this adventure with the Hourly subway dataset‚Äîa gold mine that reveals the fluctuations in commuter traffic at particular times. It feels like you are experiencing the minute-by-minute rhythmic pulse of the city's heartbeat. Every data point is a station stop, a split second captured in time, eagerly awaiting our team's deciphering of the patterns that make this subway symphony tick.\n",
    "\n",
    "But we're not simply riding the data waves. The Subway station information provides us with the precise coordinates of all 496 stations, transforming our surfboards into precision instruments for traversing the immense expanse of the metropolis. We're not simply analyzing; we're locating, examining, and revealing the subway network's geographic tapestry.\n",
    "\n",
    "\n",
    "### Research Questions:\n",
    "\n",
    "- Are there significant differences in frequency of use and passenger flow across different subway lines?\n",
    "\n",
    "- How does subway ridership in New York City vary between weekdays and weekends across different time periods of the day?\n",
    "\n",
    "- Do you predict specific holidays to cause more surges over others? For example, New Year's Eve and Thanksgiving.\n",
    "\n",
    "- Which subway route experiences the highest level of crowding with respect to time?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nXpl3gCSkJEU",
   "metadata": {
    "id": "nXpl3gCSkJEU"
   },
   "source": [
    "### Datasets\n",
    "The datasets are hosted on data.ny.gov <br>\n",
    "#### üöá NYC Subway Station Ridership Dataset Overview <br>\n",
    "This dataset provides subway ridership estimates on an hourly basis. It is composed of the following gleaming threads of data:\n",
    "- üìÖ transit_timestamp: Records the date and time when ridership transactions occur, rounded down to the nearest hour for uniformity.\n",
    "- üîë station_complex_id: A unique alphanumeric code assigned to each subway station complex for identification.\n",
    "- üè∑Ô∏è station_complex: The name of the subway station complex, noting that larger complexes may represent multiple lines.\n",
    "- üó∫Ô∏è borough: Indicates which of the five boroughs the subway station serves, providing geographical segmentation.\n",
    "- üöá routes: Details the subway lines that service each station, critical for route-specific analysis.\n",
    "- üí≤ payment_method: Specifies the fare medium, OMNY or MetroCard, used for entry into the system.\n",
    "- üë§ ridership: Quantifies the total entries at each station, reflecting the volume of station use.\n",
    "- üîÑ transfers: Counts the number of free transfers at each station, a subset of the total ridership.\n",
    "- üåê latitude, longitude: Geographical coordinates for each station, essential for spatial mapping and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f000fa71",
   "metadata": {
    "id": "f000fa71"
   },
   "source": [
    "#### üöá NYC Subway Station Dataset <br>\n",
    "A dataset listing all subway and Staten Island Railway stations, with information on:\n",
    "- üåç Location Information: Provides exact geographical locations of each station.\n",
    "- üî¢ Station Master Reference Number (MRN): A unique code for each station, crucial for identification within MTA's network.\n",
    "- üîó Complex MRN: Identifier for station complexes, highlighting interconnected stations.\n",
    "- üÜî GTFS Stop ID: Integrates stations into wider transit datasets using the Global Transit Feed Specification system.\n",
    "- üöÜ Services: Lists MTA services stopping at each station, reflecting operational diversity.\n",
    "- üèóÔ∏è Station Structure Type: Categorizes stations by structure (e.g., Elevated, Underground), offering insight into architectural and logistical aspects.\n",
    "- ‚ôø ADA-Accessibility Status: Indicates compliance with the Americans with Disabilities Act, essential for evaluating station accessibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24040bb6",
   "metadata": {
    "id": "24040bb6"
   },
   "source": [
    "#### Choice for Heavier Grading on Data Processing or Data Analysis  :\n",
    "Our project is primarily concerned with data analysis, but it also heavily emphasizes the use of advanced data processing as a core component.  \n",
    "Our approach goes beyond the fundamentals in data processing by using spatial analysis to optimize data merging for effectiveness.We guarantee accuracy in data alignment by utilizing sophisticated methods, like geographical coordinate-based dataset comparison and joining. Moreover, the user experience is elevated by our usage of various interactive visualizations, which improve interpretability and engagement. This offers a comprehensive and perceptive examination of the dataset, going beyond traditional data analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V4mnlSb7C7a0",
   "metadata": {
    "id": "V4mnlSb7C7a0"
   },
   "source": [
    "# Phase 1: WanderQuest\n",
    "Strolling through the WanderQuest phase involves importing and tidying up data. In this phase we were able to complete our project proposal task until Data Merging. In our next phase, we will continue our journey with Data Merging.\n",
    "\n",
    "Given our datasets substantial size of millions of observations, we'll tailor the processing to suit our requirements. We'll utilize only the relevant subset of the data by focusing on a recent one year period.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98dcf8c9-b403-4173-b3ea-c3d749608be6",
   "metadata": {
    "id": "98dcf8c9-b403-4173-b3ea-c3d749608be6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7IdsyhWhSnwU",
   "metadata": {
    "id": "7IdsyhWhSnwU"
   },
   "source": [
    "Our collection contains vital information about subway stations, including their geographic locations, structural characteristics, and accessibility aspects. Prepare to explore the city's transit environment with these various data points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65b1d29-acf0-4ac1-9e40-1589a554f3b4",
   "metadata": {
    "id": "d65b1d29-acf0-4ac1-9e40-1589a554f3b4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read all the data sources\n",
    "stations_df = pd.read_csv('https://storage.googleapis.com/budt-2023-0503-04/MTA_Subway_Stations_20231106.csv')\n",
    "riders_df = pd.read_csv('https://storage.googleapis.com/budt-2023-0503-04/MTA_Subway_Hourly_Ridership__Beginning_February_2022_20231106.csv')\n",
    "\n",
    "\n",
    "# Scrape off public holidays and observance like christmas, valentine's day, etc from 1st april 2022 to 31st march 2023\n",
    "holiday_2022_og = pd.read_html('https://www.timeanddate.com/holidays/us/2022', header=0)[0]\n",
    "holiday_2023_og = pd.read_html('https://www.timeanddate.com/holidays/us/2023', header=0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H8uDLGvhT8VU",
   "metadata": {
    "id": "H8uDLGvhT8VU"
   },
   "source": [
    "\n",
    "\n",
    "Continuing our investigation, we now present the Subway Hourly Ridership DataFrame. It records the city's heartbeat through the comings and goings of subway commuters and is loaded with hourly data. This information, together with our station data, lays the groundwork for a full story of urban transit. Stay tuned as we delve deeper into the rhythms and patterns of metro life!\n",
    "\n",
    "# Data Processing Steps\n",
    "\n",
    "The following steps outline the data processing performed on two datasets: `stations_df` and `riders_df`.\n",
    "\n",
    "## Processing `stations_df`\n",
    "1. **Column Removal**: Redundant columns such as 'ADA', 'ADA Notes', 'North Direction Label', 'South Direction Label', and 'Georeference' are removed. The 'Georeference' column, being a derived column from 'Longitude' and 'Latitude', is not needed.\n",
    "   \n",
    "2. **Reindexing**: The DataFrame is reindexed to use 'Station ID' as the key, facilitating easier access and manipulation based on station identifiers.\n",
    "\n",
    "## Processing `riders_df`\n",
    "1. **Null Row Removal**: All rows containing null values are identified and removed. This step ensures data completeness and integrity.\n",
    "\n",
    "2. **Column Removal**: Similar to `stations_df`, unnecessary columns like 'Georeference' and 'itsuid' are dropped from `riders_df`.\n",
    "\n",
    "3. **Regex Application on Timestamp**: A regular expression pattern (`\\d{2}\\/\\d{2}\\/\\d{4} \\d{2}:\\d{2}:\\d{2} [AP]M`) is applied to the 'transit_timestamp' column. This process creates a boolean series indicating whether each timestamp matches the specified format.\n",
    "\n",
    "4. **Timestamp Processing**: Since converting all timestamps to pandas datetime format for 12 million records is inefficient, the 'transit_timestamp' is split into two new columns, 'Date' and 'Time'. This step simplifies the manipulation and analysis of time-related data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac07795-698e-45e2-b649-7b538ecfc516",
   "metadata": {
    "id": "0ac07795-698e-45e2-b649-7b538ecfc516",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "\n",
    "# Remove redeuntant column : ADA, ADA Notes. and Direction Labels.\n",
    "# Remove Georeference as that is derived column made with Longitude + Latitude\n",
    "stations_df_edited = stations_df.drop(columns=['ADA', 'ADA Notes', 'North Direction Label', 'South Direction Label', 'Georeference'])\n",
    "\n",
    "# Reindex to station ID as key\n",
    "stations_df_edited.set_index('Station ID')\n",
    "\n",
    "# Check for null rows and drop those rows.\n",
    "riders_df_edited = riders_df.dropna().copy()\n",
    "\n",
    "# dropping the Georefercne, itsuid columns.\n",
    "riders_df_edited.drop(columns=['Georeference', 'itsuid'], inplace=True)\n",
    "\n",
    "# Apply the regex to the 'timestamp' column to create a boolean series\n",
    "pattern = r'\\d{2}\\/\\d{2}\\/\\d{4} \\d{2}:\\d{2}:\\d{2} [AP]M'\n",
    "matches_format = riders_df_edited['transit_timestamp'].str.match(pattern)\n",
    "\n",
    "# conver all timestamp to pandas data time will be a slow process as converting 12 million records is not an optimized way.\n",
    "# splitting the timestamp to time and date.\n",
    "riders_df_edited[['Date', 'Time']] = riders_df_edited['transit_timestamp'].str.split(' \\d', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1e04e-aa82-441f-b676-43c66ed8faa6",
   "metadata": {
    "id": "42a1e04e-aa82-441f-b676-43c66ed8faa6"
   },
   "source": [
    "# Filtering and Categorizing Ridership Data\n",
    "\n",
    "The code snippet focuses on processing the `riders_df_edited` DataFrame to filter and categorize ridership data based on specific time periods within a given date range.\n",
    "\n",
    "## Date Filtering\n",
    "- **Date Range**: The data is filtered for the period from April 1, 2022, to March 31, 2023.\n",
    "- **Date Formatting**: The 'Date' column is split into 'year' and 'month_day' to facilitate filtering.\n",
    "- **Filter Application**: The DataFrame is filtered to include records within the specified date range, using conditions on the 'year' and 'month_day' columns.\n",
    "\n",
    "## Time Correction and Conversion\n",
    "- **Time Correction**: The 'Time' column is corrected for midnight and noon representations ('0:00:00 AM' to '12:00:00 AM' and '0:00:00 PM' to '12:00:00 PM').\n",
    "- **Time Conversion**: The corrected 'Time' values are then converted to datetime objects for easier manipulation.\n",
    "\n",
    "## Categorization of Time Periods\n",
    "- **Function Definition**: A function `categorize_time_period` is defined to categorize time into four periods:\n",
    "  - 'Morning Rush' (6 AM to 12 PM)\n",
    "  - 'Afternoon Rush' (12 PM to 5 PM)\n",
    "  - 'Evening Rush' (5 PM to 9 PM)\n",
    "  - 'Rest of the Day' (9 PM to 6 AM).\n",
    "- **Application**: This function can be applied to the DataFrame to categorize each record based on its time, aiding in the analysis of ridership patterns during different times of the day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55080484-87d6-429b-ba8b-8349ec9d7540",
   "metadata": {
    "id": "55080484-87d6-429b-ba8b-8349ec9d7540",
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = '04/01/2022'\n",
    "end_date = '03/31/2023'\n",
    "\n",
    "# Format the start and end dates to match the DataFrame's date format\n",
    "start_date_formatted = pd.to_datetime(start_date, format='%m/%d/%Y')\n",
    "end_date_formatted = pd.to_datetime(end_date, format='%m/%d/%Y')\n",
    "\n",
    "riders_df_edited['year'] = riders_df_edited['Date'].str.slice(start=6, stop=10)\n",
    "riders_df_edited['month_day'] = riders_df_edited['Date'].str.slice(start=0, stop=5)\n",
    "riders_df_edited.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "filtered_ridership_df = riders_df_edited[((riders_df_edited['year'] == '2022') & (riders_df_edited['month_day'] >= '04/01')) |\n",
    "                 ((riders_df_edited['year'] == '2023') & (riders_df_edited['month_day'] <= '03/31'))].copy()\n",
    "\n",
    "# Format some timstamps correctly\n",
    "filtered_ridership_df['Time'] = filtered_ridership_df['Time'].str.replace('0:00:00 AM', '12:00:00 AM')\n",
    "filtered_ridership_df['Time'] = filtered_ridership_df['Time'].str.replace('0:00:00 PM', '12:00:00 PM')\n",
    "\n",
    "# convert time to datetime object\n",
    "filtered_ridership_df['Time'] = pd.to_datetime(filtered_ridership_df['Time'], format='%I:%M:%S %p').dt.time\n",
    "\n",
    "# Function to categorize time into periods\n",
    "def categorize_time_period(time):\n",
    "    # Period 1 : 6am to 12pm -- Morning rush\n",
    "    if time >= datetime.time(6, 0) and time < datetime.time(12, 0):\n",
    "        return 'Morning Rush'\n",
    "    # Period 2 : 12pm to 5pm -- Afternoon rush\n",
    "    elif time >= datetime.time(12, 0) and time < datetime.time(17, 0):\n",
    "        return 'Afternoon Rush'\n",
    "    # Period 3 : 5pm to 9pm -- Evening Rush\n",
    "    elif time >= datetime.time(17, 0) and time < datetime.time(21, 0):\n",
    "        return 'Evening Rush'\n",
    "    # Period 4 : 9pm to 6am -- Rest of the day\n",
    "    else:\n",
    "        return 'Rest of the Day'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45b40f-bec9-4763-a14f-b6a5e8a6b3e3",
   "metadata": {
    "id": "db45b40f-bec9-4763-a14f-b6a5e8a6b3e3",
    "tags": []
   },
   "source": [
    "# Merging for Ridership Analysis\n",
    "\n",
    "The code performs complex data processing and merging operations on the `filtered_ridership_df` DataFrame to analyze ridership data in relation to station data. The following steps are executed:\n",
    "\n",
    "## Categorization of Time Periods\n",
    "- **Time Period Categorization**: The `categorize_time_period` function is applied to the 'Time' column, adding a new 'Time Period' column to `filtered_ridership_df`.\n",
    "- **Timestamp Conversion**: The 'transit_timestamp' column is converted to a pandas datetime object for filtering.\n",
    "\n",
    "## Data Filtering\n",
    "- **Filtering Based on Date Range**: The DataFrame is filtered to include records within the specified date range using the `between` method.\n",
    "\n",
    "## Geographical Data Processing\n",
    "- **Grouping and Aggregating**: Data is grouped by 'station_complex_id' and 'station_complex', aggregating latitude and longitude to their mean values.\n",
    "- **Finding Nearest Points**: A function `find_nearest_point` is defined to find the nearest station point for each row in `df_visual`, based on latitude and longitude.\n",
    "\n",
    "## DataFrame Merging\n",
    "- **Joining DataFrames**: The `find_nearest_point` function is applied to `df_merge` to join it with `stations_df_edited`, creating `joined_df2`.\n",
    "- **Concatenation**: `df_merge` and `joined_df2` are concatenated to form `result_df`.\n",
    "- **Merging with Station Data**: `result_df` is merged with `stations_df_edited` based on latitude and longitude, creating `station_df`.\n",
    "- **Final Merge**: `df_visual` is merged with `station_df` on 'station_complex_id', resulting in `merged_df`.\n",
    "\n",
    "## Additional Data Processing\n",
    "- **Datetime Conversion**: A new 'datetime' column is created in `merged_df` by converting the 'year', 'month_day', and 'Time' columns to a datetime format.\n",
    "- **Day of Week Column**: A new 'Day of Week' column is added, which contains the name of the day for each date.\n",
    "- **Weekday/Weekend Categorization**: A 'Weekday/Weekend' column is created, categorizing each day as either a 'Weekend' or a 'Weekday'.\n",
    "- **Aggregation and Sorting**: Finally, the DataFrame is grouped by 'station_complex_id' and 'Stop Name', aggregating 'ridership' and sorting the results in descending order.\n",
    "\n",
    "Through these steps, the data is enriched and structured to enable in-depth analysis of ridership patterns in relation to geographical locations and time factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71717f94-76f5-4031-9226-b97bad9ae5ec",
   "metadata": {
    "id": "71717f94-76f5-4031-9226-b97bad9ae5ec",
    "outputId": "6f7eef3c-53c0-4d95-d962-b92d018d1365",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply function to a Time Period\n",
    "filtered_ridership_df['Time Period'] = filtered_ridership_df['Time'].apply(categorize_time_period)\n",
    "filtered_ridership_df['transit_timestamp'] = pd.to_datetime(filtered_ridership_df['transit_timestamp'])\n",
    "df_visual = filtered_ridership_df[filtered_ridership_df['transit_timestamp'].between(start_date_formatted, end_date_formatted)]\n",
    "\n",
    "df_merge=df_visual.groupby(['station_complex_id','station_complex']).agg({'latitude': 'mean','longitude': 'mean'})\n",
    "\n",
    "# Function to find the nearest point in stations_df_edited for each point in df_visual\n",
    "def find_nearest_point(row, df2):\n",
    "    distances = cdist([(row['latitude'], row['longitude'])], df2[['GTFS Latitude', 'GTFS Longitude']])\n",
    "    idx_min_distance = distances.argmin()\n",
    "    nearest_point = df2.iloc[idx_min_distance]\n",
    "    return pd.Series(nearest_point[['GTFS Latitude', 'GTFS Longitude']])\n",
    "\n",
    "# Apply the function to create a new DataFrame with the joined data\n",
    "joined_df2 = df_merge.apply(find_nearest_point, axis=1, df2=stations_df_edited)\n",
    "\n",
    "# Rename columns for clarity\n",
    "#joined_df2.columns = ['Nearest_Latitude', 'Nearest_Longitude']\n",
    "\n",
    "# Concatenate the original df_visual and the joined_df\n",
    "result_df = pd.concat([df_merge, joined_df2], axis=1)\n",
    "\n",
    "result_df=result_df.reset_index()\n",
    "station_df = pd.merge(result_df, stations_df_edited, left_on=['GTFS Latitude','GTFS Longitude'], right_on=['GTFS Latitude','GTFS Longitude'], how='left')\n",
    "\n",
    "# Merge based on the new station_complex_id column\n",
    "merged_df = pd.merge(df_visual, station_df, left_on='station_complex_id', right_on='station_complex_id', how='left')\n",
    "\n",
    "# Convert 'Time' to datetime format\n",
    "merged_df['datetime'] = pd.to_datetime(merged_df['year'].astype(str) + '-' + merged_df['month_day'].astype(str) + ' ' + merged_df['Time'].astype(str), format='%Y-%m/%d %H:%M:%S')\n",
    "# Create a new column 'Day of Week'\n",
    "merged_df['Day of Week'] = merged_df['datetime'].dt.day_name()\n",
    "\n",
    "# Create a new column 'Weekday/Weekend'\n",
    "merged_df['Weekday/Weekend'] = merged_df['datetime'].dt.day_name().apply(lambda x: 'Weekend' if x in ['Saturday', 'Sunday'] else 'Weekday')\n",
    "merged_df.groupby(['station_complex_id','Stop Name']).agg({'ridership': 'sum'}).sort_values(by='ridership',ascending=False).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NZnjLxfp1t9k",
   "metadata": {
    "id": "NZnjLxfp1t9k"
   },
   "source": [
    "# Phase 2: VisualVoyage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lewDHcIW1poo",
   "metadata": {
    "id": "lewDHcIW1poo"
   },
   "source": [
    "## Ridership Distribution by Subway Line\n",
    "\n",
    "### Preface\n",
    "This investigation looks at trends of subway ridership in each line. Comprehending the reasons behind the elevated passenger density on these lines illuminates the dynamics of urban commuting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae56e4e-8951-4f67-97fc-8cb0dba8f57a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eae56e4e-8951-4f67-97fc-8cb0dba8f57a",
    "outputId": "b12fe174-b94f-408f-8505-88b1de9e54be",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=merged_df\n",
    "# Calculate average ridership for each subway line and time period\n",
    "average_ridership_data = df.groupby(['Time Period', 'Line'])['ridership'].mean().reset_index()\n",
    "\n",
    "\n",
    "time_period_order = ['Morning Rush', 'Afternoon Rush', 'Evening Rush', 'Rest of the Day']\n",
    "\n",
    "# Create a heatmap for average ridership\n",
    "fig = px.imshow(pd.pivot_table(average_ridership_data, values='ridership', index='Time Period', columns='Line'),\n",
    "                x=average_ridership_data['Line'].unique(),\n",
    "                y=time_period_order,\n",
    "                color_continuous_scale='Viridis',\n",
    "                title='Average Ridership Heatmap')\n",
    "\n",
    "\n",
    "\n",
    "# Add label.\n",
    "fig.update_xaxes(title_text='Subway Line')\n",
    "fig.update_yaxes(title_text='Time Period')\n",
    "fig.update_coloraxes(colorbar_title='Ridership')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "onYSLNr92fDY",
   "metadata": {
    "id": "onYSLNr92fDY"
   },
   "source": [
    "### Emphasis on Subway line\n",
    "It's important to look at eveningtime rush hour:\n",
    "- **6th Avenue Culver St Line:** This line, which connects key boroughs and covers East Manhattan, helps to increase evening density.\n",
    "- **8th Avenue Line and Crosstown Line:** Higher density is a result of well-planned route linkages. With its role as a cross-borough link, it sees a spike in evening commuter traffic.\n",
    "\n",
    "### Causes of Greater Evening Density\n",
    "\n",
    "1. **Geographic Coverage:** More evening commuters are drawn to lines that connect boroughs.\n",
    "2. **Interconnectivity:** During nighttime transfers, there is an increased density of important interchanges and connectors.\n",
    "The proximity of employment centers to major business regions has an impact on evening ridership.\n",
    "4. **Strategic Route Planning:** Increased passenger density is a result of well-planned routes connecting important locations.\n",
    "\n",
    "### Final Thoughts\n",
    "An examination of evening ridership on particular subway lines demonstrates the complex interplay between smart route design and commuter behavior. Also using this information the Metro officials can take decision in further planning regarding linking diffrent lines and expanding network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "akgkVC75NJFz",
   "metadata": {
    "id": "akgkVC75NJFz"
   },
   "source": [
    "# Ridership Distribution by routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e157d16",
   "metadata": {},
   "source": [
    "<p>\n",
    "   <img src=\"https://storage.googleapis.com/budt704-2023/newyork.jpeg\" alt=\"Logo\" width=\"700\"/>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0547a99c",
   "metadata": {},
   "source": [
    "### Preface\n",
    "\n",
    "The motive behind this Visualization is to find the most crowded subway route in Newyork. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d61561-feb6-40ee-ada4-0da0735a21f7",
   "metadata": {
    "id": "d4d61561-feb6-40ee-ada4-0da0735a21f7",
    "outputId": "527f5e0f-e4c5-45d6-d8e5-af63f1dee745",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by the station, route, date (year + montday), + time period\n",
    "grouped_df = filtered_ridership_df.groupby(['station_complex_id', 'year', 'month_day', 'Time Period', 'routes', 'payment_method', 'borough'])\\\n",
    "                                   .agg({'ridership': 'sum', 'transfers': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "# Aggregate the data to find the average ridership for each route and time period\n",
    "average_ridership = grouped_df.groupby(['routes', 'Time Period'])['ridership'].mean().reset_index()\n",
    "\n",
    "# Pivot the data to get 'Time Period' as columns and routes as rows for plotting\n",
    "pivot_df = average_ridership.pivot(index='routes', columns='Time Period', values='ridership')\n",
    "\n",
    "# Reorder the columns of pivot_df to match the desired time period order\n",
    "pivot_df = pivot_df[time_period_order]\n",
    "\n",
    "# Find the top 10 routes with the highest average ridership\n",
    "top_routes = pivot_df.mean(axis=1).nlargest(10).index\n",
    "\n",
    "# Plotting the line graph\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Plot a line for each of the top 20 routes\n",
    "for route in top_routes:\n",
    "    line_data = pivot_df.loc[route, time_period_order]\n",
    "    ax.plot(pivot_df.columns, line_data, marker='o', label=route, linewidth=2.5)\n",
    "    # Annotate each point on this line\n",
    "    for time_period in time_period_order:\n",
    "        ridership = pivot_df.loc[route, time_period]\n",
    "        ax.annotate(f'{ridership:.0f}',\n",
    "                    (pivot_df.columns.get_loc(time_period), ridership),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(0,10),\n",
    "                    ha='center')\n",
    "\n",
    "# Setting the labels and title\n",
    "ax.set_xlabel('Time Period')\n",
    "ax.set_ylabel('Average Ridership')\n",
    "ax.set_title('Average Ridership for Different Time Periods by Route')\n",
    "\n",
    "# Set the x-ticks to the ordered time periods\n",
    "ax.set_xticks(range(len(time_period_order)))\n",
    "ax.set_xticklabels(time_period_order, rotation=45)\n",
    "\n",
    "# Add a legend for the top 20 routes\n",
    "ax.legend(title='Route', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a109c-b2e9-4405-a5f1-f261ad61ef44",
   "metadata": {
    "id": "e61a109c-b2e9-4405-a5f1-f261ad61ef44",
    "outputId": "b5c73f34-776d-4b90-dca9-eb9b54a9dadd",
    "tags": []
   },
   "source": [
    "### This picture shows the average ridership of the highest 10 routes during different time period.\n",
    "\n",
    "\n",
    "- The \"Afternoon Rush\" and \"Evening Rush\" have higher ridership than other time periods. The highest peak of ridership is indeed during the Afternoon Rush, with the most used route reaching 22,686. This observation suggests that there may be significant travel activity in the afternoon and evening in New York City, possibly due to people returning from work or school, running errands, or other social activities that typically occur in the latter part of the day.\n",
    "\n",
    "- The route with the highest ridership(blue route), which remains high volumn across all time periods, likely serves as the major transit routes. These routes may be the central routes in the network, possibly located in a densely populated area or a business district, where a high concentration of people rely on public transportation throughout the day.\n",
    "\n",
    "- The morning rush seems have same level with the rush in rest of the day, which could imply that morning peak is not that obvious in subway in New York City. People may not like using subway as their transoprtaion tools in the morning.  \n",
    "\n",
    "- The routes with consistently high ridership could be a focal point for congestion management strategies. This might include measures like fare adjustments during peak times, improved routes facilities, or targeted traffic flow management. Specific services could be targeted to meet the afternoon demand, such as express routes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bWS7b_yF3vzi",
   "metadata": {
    "id": "bWS7b_yF3vzi"
   },
   "source": [
    "## Weekday vs Weekend: Time Period Analysis\n",
    "\n",
    "### Preface\n",
    "\n",
    "Interactive and user-friendly interface for exploring data on subway stations. With this method, consumers may easily look into trends in station crowdedness. Users may quickly switch between weekdays and weekends with the use of simple elements like dropdown menus and animation frames, which also provide important information regarding commuter patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979460ed-4e11-4cf0-af0d-63b55a63dbd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "979460ed-4e11-4cf0-af0d-63b55a63dbd2",
    "outputId": "b5c73f34-776d-4b90-dca9-eb9b54a9dadd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate the ridership data.\n",
    "grouped_df = merged_df.groupby(['station_complex_id','Stop Name', 'Weekday/Weekend', 'Time Period']).agg({'ridership': 'mean','latitude_x':'mean','longitude_x':'mean'}).reset_index()\n",
    "\n",
    "# Rounding up ridership\n",
    "grouped_df['ridership']=grouped_df['ridership'].round()\n",
    "\n",
    "# To set center for visulization.\n",
    "median_lat = grouped_df['latitude_x'].median()\n",
    "median_lon = grouped_df['longitude_x'].median()\n",
    "\n",
    "# Plot map using plotly.\n",
    "fig = px.scatter_mapbox(grouped_df,\n",
    "                        lat='latitude_x',\n",
    "                        lon='longitude_x',\n",
    "                        color='ridership',\n",
    "                        size='ridership',\n",
    "                        hover_name='Stop Name',\n",
    "                        animation_frame='Time Period',\n",
    "                        color_continuous_scale='Viridis',\n",
    "                        size_max=40,\n",
    "                        mapbox_style=\"carto-positron\",\n",
    "                        zoom=10,\n",
    "                        title='Exploring Dynamic Station Crowdedness Patterns Over Time')\n",
    "\n",
    "fig.update_layout(updatemenus=[dict(type='buttons', showactive=False, buttons=[dict(label=value, method='animate', args=[{'frame': {'duration': 500, 'redraw': True}, 'fromcurrent': True, 'transition': {'duration': 300}}], ) for value in ['Value1', 'Value2', 'Value3']])])\n",
    "\n",
    "\n",
    "#App initialization using dash.\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout definition\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='weekday-weekend-dropdown',\n",
    "        options=[\n",
    "            {'label': value, 'value': value}\n",
    "            for value in grouped_df['Weekday/Weekend'].unique()\n",
    "        ],\n",
    "        value=grouped_df['Weekday/Weekend'].unique()[0],\n",
    "        multi=False,\n",
    "        clearable=False,\n",
    "        style={'width': '50%'}\n",
    "    ),\n",
    "    dcc.Graph(\n",
    "        id='scatter-mapbox-fig',\n",
    "        figure=fig,\n",
    "        style={'width': '100%', 'height': '100vh'}\n",
    "        # Width and height as needed\n",
    "    )\n",
    "])\n",
    "\n",
    "#Update the figure based on dropdown selection\n",
    "@app.callback(\n",
    "    Output('scatter-mapbox-fig', 'figure'),\n",
    "    [Input('weekday-weekend-dropdown', 'value')]\n",
    ")\n",
    "def update_figure(selected_value):\n",
    "\n",
    "    filtered_data = grouped_df[grouped_df['Weekday/Weekend'] == selected_value]\n",
    "\n",
    "    updated_fig = px.scatter_mapbox(filtered_data,\n",
    "                                   lat='latitude_x',\n",
    "                                    lon='longitude_x',\n",
    "                                    color='ridership',\n",
    "                                    size='ridership',\n",
    "                                    hover_name='Stop Name',\n",
    "                                    animation_frame='Time Period',\n",
    "                                    color_continuous_scale='Viridis',\n",
    "                                    size_max=40,\n",
    "                                    mapbox_style=\"carto-positron\",\n",
    "                                    zoom=10,\n",
    "                                    title=f'Station Crowdedness: {selected_value}')\n",
    "    # Set center for visulization.\n",
    "    updated_fig.update_layout(\n",
    "        mapbox=dict(\n",
    "            center=dict(lat=median_lat, lon=median_lon)\n",
    "\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return updated_fig\n",
    "\n",
    "\n",
    "\n",
    "#Run\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8070)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a026f-5575-4c60-8fdc-e68c61d55338",
   "metadata": {
    "id": "d93a026f-5575-4c60-8fdc-e68c61d55338",
    "outputId": "b5c73f34-776d-4b90-dca9-eb9b54a9dadd",
    "tags": []
   },
   "source": [
    "1. **Strategic Location:**\n",
    "   In the center of Manhattan, stations such as 32nd Street Herald Square, 42nd Street Grand Central, and 14th Street Union Square are ideally situated to serve as major entry points for commuters and tourists traveling through the vast underground network of the city.\n",
    "2. **Major Interchanges:**\n",
    "   Important crossroads for several subway lines, these stations are always busy with commuters switching between lines. The constant crowding of the stations is partly caused by the convergence of subway lines.\n",
    "3. **Commercial and Cultural Hubs:**\n",
    "   The neighborhoods that surround these stations are teeming with stores, workplaces, and historical sites. The stations' constant high foot traffic is increased by the constant stream of people drawn by their proximity to busy urban activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7HhF_czCg4C_",
   "metadata": {
    "id": "7HhF_czCg4C_"
   },
   "source": [
    "## Everyone Loves Holidays\n",
    "\n",
    "Here's a summary of the holiday data refinement:\n",
    "\n",
    "1. **Redundancy Removal:** Extraneous rows are removed, resulting in a more streamlined dataset.\n",
    "\n",
    "2. **Date Formatting and Renaming:** The 'Date' column is uniformly formatted, and extraneous columns are renamed to improve readability.\n",
    "\n",
    "3. **Related Holidays Filtering:** We concentrate on Federal Holidays and Observances that fall within our target date range, resulting in a succinct dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ea61e-0cab-458c-89d2-b70f49a60adf",
   "metadata": {
    "id": "673ea61e-0cab-458c-89d2-b70f49a60adf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the redundant rows we got from scrapping.\n",
    "# Scrape off public holidays and observance like christmas, valentine's day, etc from 1st april 2022 to 31st march 2023\n",
    "holiday_2022_og = pd.read_html('https://www.timeanddate.com/holidays/us/2022', header=0)[0]\n",
    "holiday_2023_og = pd.read_html('https://www.timeanddate.com/holidays/us/2023', header=0)[0]\n",
    "holiday_2022 = holiday_2022_og[2:len(holiday_2022_og)-1]\n",
    "holiday_2023 = holiday_2022_og[2:len(holiday_2022_og)-1]\n",
    "\n",
    "# Rename some columns\n",
    "holiday_2022 = holiday_2022.rename(columns={'Unnamed: 1': 'Day'})\n",
    "holiday_2023 = holiday_2023.rename(columns={'Unnamed: 1': 'Day'})\n",
    "\n",
    "# Delete reduntant columns\n",
    "holiday_2022 = holiday_2022.drop(columns='Details')\n",
    "holiday_2023 = holiday_2023.drop(columns='Details')\n",
    "\n",
    "holiday_2022['Date'] = pd.to_datetime(holiday_2022['Date'] + ' 2022')\n",
    "holiday_2023['Date'] = pd.to_datetime(holiday_2023['Date'] + ' 2022')\n",
    "\n",
    "# Federal Holiday, Observance are the two types of Holidays we are interested in. Mask with the date range we are interested in\n",
    "mask_2022 = (((holiday_2022['Type'] == 'Federal Holiday') | (holiday_2022['Type'] == 'Observance')) & (holiday_2022['Date'] >= '2022-04-01'))\n",
    "holiday_2022 = holiday_2022[mask_2022].groupby('Date').agg({'Name': '; '.join }).reset_index()\n",
    "\n",
    "mask_2023 = (((holiday_2023['Type'] == 'Federal Holiday') | (holiday_2023['Type'] == 'Observance')) & (holiday_2023['Date'] < '2022-04-01'))\n",
    "holiday_2023 = holiday_2023[mask_2023].groupby('Date').agg({'Name': '; '.join }).reset_index()\n",
    "\n",
    "# Combine the filtered holidays\n",
    "holiday_df = pd.concat([holiday_2022, holiday_2023], axis=0).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead764ea-34c7-43e2-b760-e40b713a148c",
   "metadata": {
    "id": "ead764ea-34c7-43e2-b760-e40b713a148c",
    "outputId": "77624f48-7428-4343-d6f3-757d01ccd8f2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by the station, route, date (year + montday), + time period\n",
    "hourly_data = filtered_ridership_df\n",
    "holiday_data = holiday_df\n",
    "# Convert 'month_day' and 'Date' to datetime objects for merging\n",
    "hourly_data['month_day'] = pd.to_datetime(hourly_data['year'].astype(str) + '-' + hourly_data['month_day'], format='%Y-%m/%d')\n",
    "holiday_data['Date'] = pd.to_datetime(holiday_data['Date'])\n",
    "\n",
    "# Merge datasets on date\n",
    "merged_data = pd.merge(hourly_data, holiday_data, left_on='month_day', right_on='Date', how='left')\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"NYC Subway Ridership During Holidays\"),\n",
    "    dcc.Dropdown(\n",
    "        id='holiday-dropdown',\n",
    "        options=[{'label': h, 'value': h} for h in holiday_data['Name'].unique()],\n",
    "        value=['New Year\\'s Eve', 'Thanksgiving Day'],\n",
    "        multi=True\n",
    "    ),\n",
    "    dcc.Graph(id='ridership-map'),\n",
    "    dcc.Graph(id='ridership-line-chart')\n",
    "])\n",
    "\n",
    "# Define callback for updating the map\n",
    "@app.callback(\n",
    "    Output('ridership-map', 'figure'),\n",
    "    [Input('holiday-dropdown', 'value')]\n",
    ")\n",
    "def update_map(selected_holidays):\n",
    "    # Filter data based on selected holidays\n",
    "    filtered_data = merged_data[merged_data['Name'].isin(selected_holidays)]\n",
    "\n",
    "    # Plot the map\n",
    "    fig_map = px.scatter_mapbox(\n",
    "        filtered_data,\n",
    "        lat='latitude',\n",
    "        lon='longitude',\n",
    "        hover_name='station_complex_id',\n",
    "        color='ridership',\n",
    "        size='ridership',\n",
    "        zoom=10,\n",
    "        center={\"lat\": 40.7128, \"lon\": -74.0060},\n",
    "        mapbox_style='open-street-map'\n",
    "    )\n",
    "    return fig_map\n",
    "\n",
    "# Define callback for updating the line chart\n",
    "@app.callback(\n",
    "    Output('ridership-line-chart', 'figure'),\n",
    "    [Input('holiday-dropdown', 'value')]\n",
    ")\n",
    "def update_line_chart(selected_holidays):\n",
    "    # Filter data based on selected holidays\n",
    "    filtered_data = merged_data[merged_data['Name'].isin(selected_holidays)]\n",
    "\n",
    "    # Group by date and aggregate ridership\n",
    "    grouped_data = filtered_data.groupby(['month_day', 'Name']).agg({'ridership': 'sum'}).reset_index()\n",
    "\n",
    "    # Plot the line chart\n",
    "    fig_line = px.line(\n",
    "        grouped_data,\n",
    "        x='month_day',\n",
    "        y='ridership',\n",
    "        color='Name',\n",
    "        markers=True,\n",
    "        title='Ridership Comparison on Selected Holidays'\n",
    "    )\n",
    "    return fig_line\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8071)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e05b9-d289-4874-9247-a6b9c19d89f6",
   "metadata": {
    "id": "0d3e05b9-d289-4874-9247-a6b9c19d89f6"
   },
   "source": [
    "\n",
    "- **Optimized Resource Management**: Understanding ridership patterns during holidays helps in efficient staffing and resource allocation at subway stations. This ensures enhanced passenger experience and operational efficiency.\n",
    "- **Targeted Marketing Campaigns**: Insights from holiday ridership trends enable businesses to tailor marketing and promotional activities. Retailers and service providers in subway stations can strategize offers and advertisements to maximize foot traffic and sales.\n",
    "- **Strategic Planning**: For city planners and transit authorities, this data is crucial for long-term infrastructure development, maintenance scheduling, and service optimization.\n",
    "\n",
    "- **Interactive Data Visualization**:\n",
    "  - **Map View**: Provides a geographical perspective of ridership, highlighting which stations are most frequented during different holidays. This can guide businesses in choosing optimal locations for advertisements or new ventures.\n",
    "  - **Comparative Analysis**: The line chart comparison of ridership across various holidays offers a clear view of peak usage times, critical for planning and strategy development.\n",
    "- **User-Driven Insights**:\n",
    "  - **Customizable Selections**: The dropdown menu allows users to select specific holidays for analysis. This feature enables tailored insights, helping businesses focus on relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfOQZ9XfKjCs",
   "metadata": {
    "id": "bfOQZ9XfKjCs"
   },
   "source": [
    "# Payment Analysis\n",
    "### Explores key facets of public transportation payment systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ocQjVpErKcH_",
   "metadata": {
    "id": "ocQjVpErKcH_"
   },
   "outputs": [],
   "source": [
    "grouped_df = filtered_ridership_df.groupby(['station_complex_id', 'year', 'month_day', 'Time Period', 'routes', 'payment_method', 'borough'])\\\n",
    "                                   .agg({'ridership': 'sum', 'transfers': 'sum'}).reset_index()\n",
    "grouped_df_pivoted = grouped_df.pivot_table(index=\"borough\", columns=\"payment_method\", values=\"ridership\")\n",
    "\n",
    "# Get the borough and payment method columns\n",
    "borough = grouped_df_pivoted.index\n",
    "payment_method = grouped_df_pivoted.columns\n",
    "\n",
    "# Create a stacked bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "grouped_df_pivoted.plot(kind=\"bar\", stacked=True)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.ylabel(\"Avverage Ridership\")\n",
    "plt.title(\"Ridership by Borough and Payment Method (Stacked Bar Plot)\")\n",
    "\n",
    "# Show the¬†plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sNREPkf-KoYv",
   "metadata": {
    "id": "sNREPkf-KoYv"
   },
   "source": [
    "### Observation:\n",
    "\n",
    "- **Metro Card Longevity:** - Due to their lengthy history, Metro cards are well-known among commuters.\n",
    "\n",
    "- **Metro Card Physical Accessibility:** - Metro cards are physically available, which promotes inclusivity by allowing those without smartphones to use them.\n",
    "\n",
    "- **Privacy and Security Issues with OMNY:** - A few commuters have expressed concerns over the digital OMNY card's privacy and security.\n",
    "\n",
    "- **Higher OMNY Adoption in Manhattan:** OMNY has a higher percentage in Manhattan, perhaps as a result of its importance as a major business and tourism hub.\n",
    "\n",
    "\n",
    "### Scope: \n",
    "- **Improved User Experience and Accessibility:**\n",
    "  - Transportation authorities can enhance payment systems by considering commuter preferences and concerns. This approach ensures a smooth and inclusive experience for all users, including those without smartphones.\n",
    "\n",
    "- **Strategic Urban Planning:**\n",
    "  - Understanding the evolving dynamics of technology adoption allows urban planners to strategically allocate resources and plan infrastructure upgrades. Insights into borough-specific adoption patterns contribute to effective planning that meets the changing needs of different parts of the city.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b4cc1-61e1-4533-8dbc-ca3fa0971be8",
   "metadata": {
    "id": "8xaxG_LT87Cd"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "In conclusion, the analysis of New York subway data plays a pivotal role in enhancing operational efficiency and commuter experience.\n",
    "- It enables the Metropolitan Transportation Authority (MTA) to effectively allocate resources, manage crowds, and make informed strategic decisions about service expansion and station upgrades.\n",
    "- Furthermore, it provides a basis for targeted marketing strategies, aligning business efforts with peak commuter activity.\n",
    "- Additionally, we got to know which routes, lines and stations are used most by passengers, it will definitely help many industries to plam there business tactics.\n",
    "- Ultimately, this comprehensive understanding of usage patterns is instrumental in improving the overall safety, comfort, and satisfaction of commuters in New York City's subway system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda58d87-8b9e-4dbe-bba6-2e568905d07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7HhF_czCg4C_",
    "bfOQZ9XfKjCs"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
